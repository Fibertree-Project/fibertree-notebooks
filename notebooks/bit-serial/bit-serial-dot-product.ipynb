{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d16cb776",
   "metadata": {},
   "source": [
    "# Bit serial computation - Dot product\n",
    "\n",
    "The notebook illustrates that bit-serial computation of a dot product of a an operand `A` by an operand `B`, where the `A` operand is a set of values viewed at the bit level. This computation can be viewed as tensor computation where the bit-level representation of `A` is achieved with a rank-2 tensor where the lower rank is a set of sparse fibers with a 1 at those coordinates that match the bit-positions with a 1 in the binary representation of the value. The operand `B` is simply represented as a rank-1 tensor of values. As a result this computation can be represented with the following Einsum:\n",
    "\n",
    "$$\n",
    "Z = A_{i,j} \\times B_i \\times 2^j\n",
    "$$\n",
    "\n",
    "This representation of the calculation allows us to consider different dataflows and parallelism options, which are illustrated below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eea89da",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "The first step is to set up the environment and create some tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d167cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run boilerplate code to set up environment\n",
    "\n",
    "%run ../prelude.py --style=tree --animation=movie"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f226db2",
   "metadata": {},
   "source": [
    "## Configure some tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4257a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default value for the number of elements in the dot product\n",
    "I = 4\n",
    "\n",
    "# Default value for the number of bits in each elemnt of the `A` tensor\n",
    "J = 8\n",
    "\n",
    "tm = TensorMaker(\"dot product inputs\")\n",
    "\n",
    "tm.addTensor(\"A_IJ\", rank_ids=[\"I\", \"J\"], shape=[I, J], density=0.6, interval=1, seed=0, color=\"blue\")\n",
    "tm.addTensor(\"B_I\", rank_ids=[\"I\"], shape=[I], density=1, seed=1, color=\"green\")\n",
    "\n",
    "tm.displayControls()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c6718c",
   "metadata": {},
   "source": [
    "## Create and display the tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d090c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_IJ = tm.makeTensor(\"A_IJ\")\n",
    "A_JI = A_IJ.swapRanks().setName(\"A_JI\")\n",
    "B_I = tm.makeTensor(\"B_I\")\n",
    "\n",
    "#\n",
    "# Calculate binary value of A from bit-wise represenation\n",
    "#\n",
    "a_values = []\n",
    "for i, a_j in A_IJ:\n",
    "    a_value = 0\n",
    "    for j, _ in a_j:\n",
    "        a_value += 2**j\n",
    "    a_values.append(a_value)\n",
    "\n",
    "print(f\"A_IJ (with values {a_values})\")\n",
    "displayTensor(A_IJ)\n",
    "\n",
    "print(\"A_JI\")\n",
    "displayTensor(A_JI)\n",
    "\n",
    "print(\"B\")\n",
    "displayTensor(B_I)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424be39b",
   "metadata": {},
   "source": [
    "## Create power array\n",
    "\n",
    "Although the original Einsum notation includes a multiplication by a value that is a function only of an index value (`2^j`), this code will express that as a multiplicaton by a value from a constant rank-1 tensor (`pow2`). In reality, this would probably be implemented directly in hardware (in this case as a **shift**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f28e43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pow2 = Tensor(rank_ids=[\"J\"], shape=[J], name=\"Pow2\", color=\"lightblue\")\n",
    "\n",
    "pow2_j = pow2.getRoot()\n",
    "\n",
    "for j, pow2_ref in pow2_j.iterShapeRef():\n",
    "    pow2_ref <<= 2 ** j\n",
    "    \n",
    "displayTensor(pow2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39556ca2",
   "metadata": {},
   "source": [
    "## Serial execution\n",
    "\n",
    "Observations:\n",
    "\n",
    "- Since both `a_i` and `b_i` are dense they can be uncompressed and their intersection in trivial\n",
    "- Since `a_j` is compressed and `pow2` can be uncompressed their intersection can be leader-follower\n",
    "- Elapsed time is proportional to the total occupancy of all the fibers in the `J` rank of `A_IJ`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c865ddb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = Tensor(rank_ids=[], name=\"Dot Prod\")\n",
    "\n",
    "a_i = A_IJ.getRoot()\n",
    "b_i = B_I.getRoot()\n",
    "pow2_j = pow2.getRoot()\n",
    "\n",
    "z_ref = z.getRoot()\n",
    "\n",
    "canvas = createCanvas(A_IJ, B_I, pow2, z)\n",
    "\n",
    "for i, (a_j, b_val) in a_i & b_i:\n",
    "    for j, (a_val, pow2_val) in a_j & pow2_j:\n",
    "        # Note a_val can only be \"1\" so we don't need to multiply by it.\n",
    "        z_ref += (a_val * b_val) * pow2_val\n",
    "        canvas.addFrame((i,j),(i,),(j,), (0,))\n",
    "        \n",
    "displayTensor(z)\n",
    "displayCanvas(canvas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b981cc",
   "metadata": {},
   "source": [
    "## Parallel across B's\n",
    "\n",
    "Observations: \n",
    "\n",
    "- Time is equal to the occupancy of the longest fiber in the `J` rank of `A`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6363c111",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = Tensor(rank_ids=[], name=\"Dot Prod\")\n",
    "\n",
    "a_i = A_IJ.getRoot()\n",
    "b_i = B_I.getRoot()\n",
    "pow2_j = pow2.getRoot()\n",
    "\n",
    "z_ref = z.getRoot()\n",
    "\n",
    "canvas = createCanvas(A_IJ, B_I, pow2, z)\n",
    "\n",
    "for i, (a_j, b_val) in a_i & b_i:\n",
    "    for n_j, (j, (a_val, pow2_val)) in enumerate(a_j & pow2_j):\n",
    "        z_ref += (a_val * b_val) * pow2_val\n",
    "        canvas.addActivity((i,j),(i,),(j,), (0,),\n",
    "                          spacetime=(i, n_j))\n",
    "        \n",
    "displayTensor(z)\n",
    "displayCanvas(canvas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771ad260",
   "metadata": {},
   "source": [
    "## Parallel across bits (with infinite parallelism)\n",
    "\n",
    "Observations:\n",
    "\n",
    "- Latency is the occupancy of the longest fibers in the `I` of the `A_JI` tensor\n",
    "\n",
    "\n",
    "Note: If there are too many \"j\"s one approximation would be to ignore low order bits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bae8d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = Tensor(rank_ids=[], name=\"Dot Prod\")\n",
    "\n",
    "a_j = A_JI.getRoot()\n",
    "b_i = B_I.getRoot()\n",
    "pow2_j = pow2.getRoot()\n",
    "\n",
    "z_ref = z.getRoot()\n",
    "\n",
    "canvas = createCanvas(A_IJ, A_JI, B_I, pow2, z)\n",
    "\n",
    "for j, (a_i, pow2_val) in a_j & pow2_j:\n",
    "    for n_i, (i, (a_val, b_val)) in enumerate(a_i & b_i):\n",
    "        z_ref += (a_val * b_val) * pow2_val\n",
    "        canvas.addActivity((i,j),(j,i),(i,),(j,), (0,),\n",
    "                          spacetime=(j, n_i))\n",
    "        \n",
    "displayTensor(z)\n",
    "displayCanvas(canvas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc13ef1",
   "metadata": {},
   "source": [
    "## Parallel across bits (limited parallelism)\n",
    "\n",
    "But limit parallelism to `I` to make fair comparison to `B` parallel. In this design, there is a barrier between the processing of each group of `I` bits, i.e., between the processing of each fiber of the `j0` rank of the split `A_JI` tensor.\n",
    "\n",
    "Observations:\n",
    "\n",
    "- Latency is the sum of the largest occupancies of the `I` rank for each of the fibers in the `j0` rank of the split `A_JI` tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a15900",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_JI_split = A_JI.splitUniform(I)\n",
    "\n",
    "displayTensor(A_JI_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63af1b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = Tensor(rank_ids=[], name=\"Dot Prod\")\n",
    "\n",
    "\n",
    "a_j1 = A_JI_split.getRoot()\n",
    "b_i = B_I.getRoot()\n",
    "pow2_j = pow2.getRoot()\n",
    "\n",
    "z_ref = z.getRoot()\n",
    "\n",
    "canvas = createCanvas(A_IJ, A_JI_split, B_I, pow2, z)\n",
    "\n",
    "for n_j1, (j1, a_j0) in enumerate(a_j1):\n",
    "    for j, (a_i, pow2_val) in a_j0 & pow2_j:\n",
    "        for n_i, (i, (a_val, b_val)) in enumerate(a_i & b_i):\n",
    "            z_ref += (a_val * b_val) * pow2_val\n",
    "            canvas.addActivity((i,j),(j1,j,i),(i,),(j,), (0,),\n",
    "                                spacetime=(j-j1, (n_j1,n_i)))\n",
    "        \n",
    "displayTensor(z)\n",
    "displayCanvas(canvas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d67b87a",
   "metadata": {},
   "source": [
    "## ## Parallel across bits (limited parallelism)\n",
    "\n",
    "Allowing slip between groups of bits, i.e., relaxes bit-level barrier. However, each PE works on a fixed position in each fiber in `a_j0`.\n",
    "\n",
    "Observation:\n",
    "\n",
    "- Each PE is busy for the sum of the occupancies of the `a_i` fibers at that PE's position in the `a_j0` fibers\n",
    "- Latency is equal long pole PE. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343c8621",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = Tensor(rank_ids=[], name=\"Dot Prod\")\n",
    "\n",
    "\n",
    "a_j1 = A_JI_split.getRoot()\n",
    "b_i = B_I.getRoot()\n",
    "pow2_j = pow2.getRoot()\n",
    "\n",
    "z_ref = z.getRoot()\n",
    "\n",
    "cycles = I*[0]\n",
    "\n",
    "canvas = createCanvas(A_IJ, A_JI_split, B_I, pow2, z)\n",
    "\n",
    "for n_j1, (j1, a_j0) in enumerate(a_j1):\n",
    "    for j, (a_i, pow2_val) in a_j0 & pow2_j:\n",
    "        for n_i, (i, (a_val, b_val)) in enumerate(a_i & b_i):\n",
    "            z_ref += (a_val * b_val) * pow2_val\n",
    "            pe = j-j1\n",
    "            canvas.addActivity((i,j),(j1,j,i),(i,),(j,), (0,),\n",
    "                                spacetime=(pe, cycles[pe]))\n",
    "            cycles[pe] += 1\n",
    "        \n",
    "displayTensor(z)\n",
    "displayCanvas(canvas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a436b63b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30301a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
