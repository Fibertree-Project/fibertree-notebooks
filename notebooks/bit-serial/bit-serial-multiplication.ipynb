{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d16cb776",
   "metadata": {},
   "source": [
    "# Bit serial computation - Multiplication\n",
    "\n",
    "The notebook illustrates how bit-serial multiplicaton of an operand `A` by an operand `B`, where the `A` operand is viewed at the bit level, can be treated as a tensor computation. This computation can be viewed as a tensor computation where the bit-level representation of `A` is achieved with a sparse fiber with a 1 at those coordinates that match the bit-positions with a 1 in the binary representation of the value. The operand `B` is simply represented as a scalar value. As a result this computation can be represented with the following Einsum:\n",
    "\n",
    "$$\n",
    "Z = A_j \\times 2^j \\times B\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eea89da",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "The first step is to set up the environment and create some tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d167cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Begin - startup boilerplate code\n",
    "\n",
    "import pkgutil\n",
    "\n",
    "if 'fibertree_bootstrap' not in [pkg.name for pkg in pkgutil.iter_modules()]:\n",
    "  !python3 -m pip  install git+https://github.com/Fibertree-project/fibertree-bootstrap --quiet\n",
    "\n",
    "# End - startup boilerplate code\n",
    "\n",
    "\n",
    "from fibertree_bootstrap import *\n",
    "fibertree_bootstrap(style=\"tree\", animation=\"movie\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f226db2",
   "metadata": {},
   "source": [
    "## Configure some tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4257a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default value for the number of bits in the operand A\n",
    "J = 8\n",
    "\n",
    "tm = TensorMaker(\"dot product inputs\")\n",
    "\n",
    "tm.addTensor(\"A_J\", rank_ids=[\"J\"], shape=[J], density=0.5, interval=1, seed=0, color=\"blue\")\n",
    "\n",
    "tm.displayControls()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c6718c",
   "metadata": {},
   "source": [
    "## Create and display the tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d090c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_J = tm.makeTensor(\"A_J\")\n",
    "\n",
    "#\n",
    "# Calculate binary value of A from bit-wise represenation\n",
    "#\n",
    "a_value = 0\n",
    "for j, _ in A_J:\n",
    "    a_value += 2**j\n",
    "\n",
    "\n",
    "B = Tensor(rank_ids=[], name=\"B\", color=\"green\")\n",
    "\n",
    "b = B.getRoot()\n",
    "b <<= 5\n",
    "\n",
    "print(f\"A_J (with value {a_value})\")\n",
    "displayTensor(A_J)\n",
    "\n",
    "print(\"B\")\n",
    "displayTensor(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424be39b",
   "metadata": {},
   "source": [
    "## Create power array\n",
    "\n",
    "Although the original Einsum notation includes a multiplication by a value that is a function only of an index value (`2^j`), this code will express that as a multiplicaton by a value from a constant rank-1 tensor (`pow2`). In reality, this would probably be implemented directly in hardware (in this case as a **shift**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f28e43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pow2 = Tensor(rank_ids=[\"J\"], shape=[J], name=\"Pow2\", color=\"lightblue\")\n",
    "\n",
    "pow2_j = pow2.getRoot()\n",
    "\n",
    "for j, pow2_ref in pow2_j.iterShapeRef():\n",
    "    pow2_ref <<= 2 ** j\n",
    "    \n",
    "displayTensor(pow2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39556ca2",
   "metadata": {},
   "source": [
    "## Serial execution\n",
    "\n",
    "Observations:\n",
    "\n",
    "- Elapsed time is proportional to the occupancy of fiber in the `J` rank of `A_J`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c865ddb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = Tensor(rank_ids=[], name=\"Product\")\n",
    "\n",
    "a_j = A_J.getRoot()\n",
    "b_val = B.getRoot()\n",
    "pow2_j = pow2.getRoot()\n",
    "\n",
    "z_ref = z.getRoot()\n",
    "\n",
    "canvas = createCanvas(A_J, B, pow2, z)\n",
    "\n",
    "for j, (a_val, pow2_val) in a_j & pow2_j:\n",
    "    z_ref += (a_val * b_val) * pow2_val\n",
    "    canvas.addFrame((j,),(0,),(j,), (0,))\n",
    "        \n",
    "displayTensor(z)\n",
    "displayCanvas(canvas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349236ae",
   "metadata": {},
   "source": [
    "## Serial computation (with optimization)\n",
    "\n",
    "Note that since the value of `a_val` must be a 1 the actual multiplication by `a_val` can be skiped... so now the code is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79c7764",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = Tensor(rank_ids=[], name=\"Product\")\n",
    "\n",
    "a_j = A_J.getRoot()\n",
    "b_val = B.getRoot()\n",
    "pow2_j = pow2.getRoot()\n",
    "\n",
    "z_ref = z.getRoot()\n",
    "\n",
    "canvas = createCanvas(A_J, B, pow2, z)\n",
    "\n",
    "for j, (a_val, pow2_val) in a_j & pow2_j:\n",
    "    # Since `a_val` must be 1 we do not need to multiply but it\n",
    "    z_ref += b_val * pow2_val\n",
    "    canvas.addFrame((j,),(0,),(j,), (0,))\n",
    "        \n",
    "displayTensor(z)\n",
    "displayCanvas(canvas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5272d17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
