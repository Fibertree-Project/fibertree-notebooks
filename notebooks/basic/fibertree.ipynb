{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Tool for manipulating tensors using the hierarchical fiber abstraction\n",
    "\n",
    "## Introduction\n",
    "\n",
    "The following cells provide an introduction to the Python operators on tensors (and other objects) in the fibertree abstraction. More background on this abstraction for representing tensors can be found sections 8.2 and 8.3 of the book [Efficient Processing of Deep Neural Networks](https://doi.org/10.2200/S01004ED1V01Y202004CAC050).\n",
    "\n",
    "First, we run some standard boilerplate code to include some libraries and create some dropdown lists to select the display style and type of animation.\n",
    "\n",
    "Note this boilerplate code will install the fibertree package, if needed, and will run in a variety of environments, including Google Colab. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Begin - startup boilerplate code\n",
    "\n",
    "import pkgutil\n",
    "\n",
    "if 'fibertree_bootstrap' not in [pkg.name for pkg in pkgutil.iter_modules()]:\n",
    "  !python3 -m pip  install git+https://github.com/Fibertree-project/fibertree-bootstrap --quiet\n",
    "\n",
    "# End - startup boilerplate code\n",
    "\n",
    "from fibertree_bootstrap import *\n",
    "fibertree_bootstrap(style=\"tree\", animation='movie')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naming conventions\n",
    "\n",
    "To make reading fiber tree-based code a bit easier, we try to use a consistent variable naming convention in this and other notebooks as follows:\n",
    "\n",
    "### Rank shapes\n",
    "\n",
    "The **shape** of a rank (and all the fibers in a rank) is the maximum number of coordinates in each fiber. Variables holding the **shape** of all the fibers in a rank is usually a single uppercase character corresponding to the the name of the rank. For example:\n",
    "\n",
    "```python\n",
    "# Fibers in ranks \"M\" and \"K\" have shapes 4 and 6, respectively\n",
    "\n",
    "M = 4\n",
    "K = 6\n",
    "```\n",
    "\n",
    "### Tensors\n",
    "\n",
    "**Tensors** are either identified by a single lowercase letter or a single lowercase letter, an underscore (\\_), and the names of the ranks in the tensor. The rank names are listed in order from top to bottom of the fiber tree. For example:\n",
    "\n",
    "```python\n",
    "# Two tensors with ranks named \"M\" and \"K\"\n",
    "\n",
    "a = Tensor(rank_ids=[\"M\", \"K\"])\n",
    "a_MK = Tensor(rank_ids=[\"M\", \"K\"])\n",
    "\n",
    "```\n",
    "\n",
    "### Fibers\n",
    "\n",
    "**Fibers** that are extracted from the ranks of a tensor are named with the lowercase name of the tensor, an underscore (\\_), and a lowercase letter matching the name of the fiber's rank. For example:\n",
    "\n",
    "```python\n",
    "# Get the root fiber from a tensor\n",
    "\n",
    "a_m = a_MK.getRoot()\n",
    "\n",
    "```\n",
    "\n",
    "Note how the naming of the variable holding the root fiber of a tensor follows from the name of the tensor.\n",
    "\n",
    "\n",
    "### Coordinates\n",
    "\n",
    "When accessing elements of a fiber one can use the **Fiber.getPayload()** to access the payload by **coordinate**. Coordinates are named with a lowercase letter corronding the the name of the fiber's rank. An example assuming the coordianates in a fiber are in the open range from 0 to \"rank shape\" and using **Fiber.getPayload()** is:\n",
    "\n",
    "```python\n",
    "\n",
    "# Get the payloads (which happen to be fibers) at each coordinate in the a_m fiber\n",
    "\n",
    "for m in range(M):\n",
    "    a_k = a_m.getPayload(m)\n",
    "    ...\n",
    "```\n",
    "\n",
    "Note how the name of the coordinate follows from the name of the fiber.\n",
    "\n",
    "This convention for coordinate and payload fiber names will also be used when iterating through a fiber in the cells below. \n",
    "\n",
    "\n",
    "### Tensor values\n",
    "\n",
    "The values as the the bottom of a tensor's fiber tree, i.e., leaf values, will be a terminal value. For Python programming language reasons, we need to distinguish between such values that are just going to be used computaionally as a input (right-hand side of an assignment) and an output (left-hand side of an assigment or update). So we use a lowercase letter corresponding to the name of the tensor followed by either \\_val or \\_ref to indicate those two cases. Such values are generated by the **Fiber.getPayload{,Ref}()** and also the fiber mutation/insertion operator (<<). For example:\n",
    "\n",
    "```python\n",
    "\n",
    "# Get the value and a reference to a fiber element's payload at the lowest rank of a tensor\n",
    "\n",
    "k = 0 \n",
    "\n",
    "a_val = a_k.getPayload(k)\n",
    "a_ref = a_k.getPayloadRef(k)\n",
    "```\n",
    "\n",
    "Note: This distinction tends to only needed at the leaf payloads of a fiber tree, since variables holding a fiber tend to behave properly as either a value or a reference.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a tensor\n",
    "\n",
    "Following is an example of reading in a tensor from a file in YAML format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display an example tensor\n",
    "\n",
    "filename = datafileName(\"draw-a.yaml\")\n",
    "\n",
    "print(\"YAML representation of a tensor\\n\")\n",
    "f = open(filename)\n",
    "for line in f:\n",
    "    print(line.rstrip('\\n'))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and display a tensor from a YAML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Tensor.fromYAMLfile(filename)\n",
    "\n",
    "print(\"Fiber-tree picture of a tensor\")\n",
    "displayTensor(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print output for fibers in the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the root fiber out of the tensor\n",
    "a_m = a.getRoot()\n",
    "\n",
    "print(\"Formatted printout of fiber\\n\")\n",
    "print(f\"{a_m}\\n\\n\")\n",
    "\n",
    "print(\"Formatted printout of fiber (with newlines)\\n\")\n",
    "print(f\"{a_m:n}\\n\\n\")\n",
    "\n",
    "print(\"Formatted printout of fiber (with newlines and no elipsis)\\n\")\n",
    "print(f\"{a_m:n*}\\n\\n\")\n",
    "\n",
    "print(\"Formatted printout of fiber (with explicit coordinate and payload format)\\n\")\n",
    "print(f\"{a_m:(02d,03d)n*}\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a tensor from an uncompressed array\n",
    "\n",
    "One can also create a tensor from an set of nested lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_data = [[0, 0, 0, 60, 70, 0, 0, 0],\n",
    "          [0, 0, 0, 0, 70, 80, 0, 0],\n",
    "          [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "          [0, 0, 0, 0, 0, 90, 100, 0]]\n",
    "\n",
    "b = Tensor.fromUncompressed([\"X\", \"Y\"], b_data)\n",
    "\n",
    "displayTensor(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a random tensor\n",
    "\n",
    "One can also create a random tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Tensor.fromRandom(rank_ids=[\"X\", \"Y\"],     # required\n",
    "                      shape=[4,6],             # required\n",
    "                      density=[1.0, 0.4],      # required\n",
    "                      name=\"C\",                # optional, default=\"\"\n",
    "                      interval=100,            # optional, default=10\n",
    "                      color=\"red\",             # optional, default=\"red\"\n",
    "                      seed=100)                # optional, default=None\n",
    "\n",
    "displayTensor(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a user configured random tensor\n",
    "\n",
    "One can also create a random tensor using user specified controls. This is done in two steps a configuration step in the cell below and an instantiation step in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Instantiate the tensor factory\n",
    "#\n",
    "tm = TensorMaker()\n",
    "\n",
    "#\n",
    "# Define the templates for two tensors\n",
    "#\n",
    "d = tm.addTensor(name=\"D\",                     # required\n",
    "                 rank_ids=[\"X\", \"Y\"],          # required\n",
    "                 shape=[4,6],                  # required\n",
    "                 density=0.4,                  # optional, default=0.2\n",
    "                 interval=9,                   # optional, default=5\n",
    "                 color=\"green\",                # optional, default=\"red\"\n",
    "                 seed=100)                     # optional, default=10\n",
    "\n",
    "e = tm.addTensor(name=\"E\",                     # required\n",
    "                 rank_ids=[\"Y\", \"X\"],          # required\n",
    "                 shape=[6,4],                  # required\n",
    "                 density=0.4,                  # optional, default=0.2\n",
    "                 interval=5,                   # optional, default=5\n",
    "                 color=\"blue\",                 # optional, default=\"red\"\n",
    "                 seed=200)                     # optional, default=10\n",
    "\n",
    "#\n",
    "# Display the controls to configure the tensors\n",
    "#\n",
    "tm.displayControls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Instantiate the named tensors defined above\n",
    "#\n",
    "d = tm.makeTensor(\"D\")\n",
    "e = tm.makeTensor(\"E\")\n",
    "\n",
    "#\n",
    "# Display the tensors\n",
    "#\n",
    "displayTensor(d)\n",
    "displayTensor(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traverse a tensor\n",
    "\n",
    "The fibers in a tensor (starting with the root fiber) can be interated over using a for loop. Each iteration returns the coordinate and payload for each element in the fiber. If the payload is itself a fiber then that fiber can be iterated over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traverse a tensor\n",
    "\n",
    "a = Tensor.fromYAMLfile(datafileName(\"matrix-a.yaml\"))\n",
    "\n",
    "displayTensor(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Animating a traversal\n",
    "\n",
    "The codebase provides some utility functions to animate the accesses to a tensor. The notebook [fibertree animation](./fibertree-animation) has more details on animating a computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "canvas = createCanvas(a)\n",
    "\n",
    "a_m = a.getRoot()\n",
    "\n",
    "for m, (a_k) in a_m:\n",
    "    print(f\"({m}, {a_k})\")\n",
    "    for k, (a_val) in a_k:\n",
    "        print(f\"Processing: ({k}, {a_val})\")\n",
    "        canvas.addActivity((m,k))\n",
    "\n",
    "displayCanvas(canvas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Element-wise update (an empty) tensor, i.e., copy\n",
    "\n",
    "To interatively update the values in a fiber one can use the mutation/insertion binary operator (<<). When given two fibers, for example \"z << a\", the operator returns a fiber that has every coordinate in \"a\" and a payload that is tuple containing a reference to the payload in \"z\" and the payload in \"a\" for those coordinates. Note that if \"z\" did not already have a element at a coordinate that exists in \"a\" then a element at that coordinate is inserted with a default value (typically zero).\n",
    "\n",
    "An in-depth exploration of the ```<<``` operator can be found at [lessthan-lessthan-operator](./lessthan-lessthan-operator.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Element-wise update a tensor\n",
    "\n",
    "a = Tensor.fromYAMLfile(datafileName(\"elementwise-a.yaml\"))\n",
    "z = Tensor(rank_ids=[\"M\"])\n",
    "\n",
    "a_m = a.getRoot()\n",
    "z_m = z.getRoot()\n",
    "\n",
    "print(\"Z < A Fiber\")\n",
    "\n",
    "canvas = createCanvas(a, z)\n",
    "\n",
    "for m, (z_ref, a_val) in z_m << a_m:\n",
    "    print(f\"Processing: ({m}, ({z_ref}, {a_val})\")\n",
    "    \n",
    "    z_ref += a_val\n",
    "    canvas.addActivity((m,), (m,))\n",
    "\n",
    "displayCanvas(canvas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intersection\n",
    "\n",
    "One can intersect the contents of two fibers using the **and** (&) operator. That operator takes two fibers as operands, and returns a fiber that has a element for each coordinate that appears in **both** input fibers and a paylaod that consists of a tuple of the corresponding payloads for the two input fibers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fiber instersection\n",
    "\n",
    "a = Tensor.fromYAMLfile(datafileName(\"elementwise-a.yaml\"))\n",
    "b = Tensor.fromYAMLfile(datafileName(\"elementwise-b.yaml\"))\n",
    "\n",
    "a_m = a.getRoot()\n",
    "b_m = b.getRoot()\n",
    "\n",
    "\n",
    "z_m = a_m & b_m\n",
    "\n",
    "print(\"Fiber a_m\")\n",
    "displayTensor(a_m)\n",
    "\n",
    "print(\"Fiber b_m\")\n",
    "displayTensor(b_m)\n",
    "\n",
    "print(\"Fiber a_m & b_m\")\n",
    "displayTensor(z_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elementwise multiply\n",
    "\n",
    "Elementwise multiply uses intersection to work on only those elements of the input fibers that each have the same coordinate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Element-wise multiply\n",
    "\n",
    "a = Tensor.fromYAMLfile(datafileName(\"elementwise-a.yaml\"))\n",
    "b = Tensor.fromYAMLfile(datafileName(\"elementwise-b.yaml\"))\n",
    "z = Tensor(rank_ids=[\"M\"])\n",
    "\n",
    "a_m = a.getRoot()\n",
    "b_m = b.getRoot()\n",
    "z_m = z.getRoot()\n",
    "\n",
    "print(\"Z < A Fiber\")\n",
    "\n",
    "canvas = createCanvas(a, b, z)\n",
    "\n",
    "for m, (z_ref, (a_val, b_val)) in z_m << (a_m & b_m):\n",
    "    print(f\"Processing: ({m}, ({z_ref}, ({a_val}, {b_val})))\")\n",
    "\n",
    "    z_ref += a_val * b_val\n",
    "    canvas.addActivity((m,), (m,), (m,))\n",
    "\n",
    "displayCanvas(canvas, width=\"75%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dot-product\n",
    "\n",
    "Here is a dot product of two tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dot product\n",
    "#\n",
    "# To perform a dot-product we need a \"row\" for an output.\n",
    "# So we represent the vectors as 2-D tensors\n",
    "#\n",
    "\n",
    "\n",
    "a = Tensor.fromYAMLfile(datafileName(\"dot-product-a.yaml\"))\n",
    "b = Tensor.fromYAMLfile(datafileName(\"dot-product-b.yaml\"))\n",
    "z = Tensor(rank_ids=[\"M\"])\n",
    "\n",
    "a_m = a.getRoot()\n",
    "b_m = b.getRoot()\n",
    "z_m = z.getRoot()\n",
    "\n",
    "canvas = createCanvas(a, b, z)\n",
    "\n",
    "for m, (z_ref, (a_k, b_k)) in z_m << (a_m & b_m):\n",
    "    for k, (a_val, b_val) in a_k & b_k:\n",
    "        print(f\"Processing: [{k} -> ( {z_ref}, ({a_val}, {b_val})]\")\n",
    "\n",
    "        z_ref += a_val * b_val\n",
    "        canvas.addActivity((m,k), (m, k), (m,))\n",
    "\n",
    "\n",
    "displayCanvas(canvas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Union\n",
    "\n",
    "One can union the contents of two fibers using the **or** (|) operator. That operator takes two fibers as operands, and returns a fiber that has a element for each coordinate that appears in **either** input fibers and a paylaod that consists of a triple containing a mask (indicating with the rest of the triple contains payload from only-A, only-B or both-A-and-B and the corresponding payloads for the two input fibers. If a fiber doesn't have a particular coordinate the default value (typically zero) is used.\n",
    "\n",
    "For a deeper dive into the union operator, see [union-operator](./union-operator.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fiber union\n",
    "\n",
    "a = Tensor.fromYAMLfile(datafileName(\"elementwise-a.yaml\"))\n",
    "b = Tensor.fromYAMLfile(datafileName(\"elementwise-b.yaml\"))\n",
    "\n",
    "\n",
    "a_m = a.getRoot()\n",
    "b_m = b.getRoot()\n",
    "\n",
    "z_m = a_m | b_m\n",
    "\n",
    "print(\"Fiber a_m\")\n",
    "displayTensor(a_m)\n",
    "\n",
    "print(\"Fiber b_m\")\n",
    "displayTensor(b_m)\n",
    "\n",
    "print(\"Fiber a_m | b_m\")\n",
    "displayTensor(z_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elementwise addition\n",
    "\n",
    "Elementwise addition uses the union operator. A more sophisiticated version could look at the mask to see if an addition is actually needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Do a sum of sums of the rows of two matrices\n",
    "#\n",
    "\n",
    "a = Tensor.fromYAMLfile(datafileName(\"dot-product-a.yaml\"))\n",
    "b = Tensor.fromYAMLfile(datafileName(\"dot-product-b.yaml\"))\n",
    "\n",
    "z = Tensor(rank_ids=[\"M\"])\n",
    "\n",
    "a_m = a.getRoot()\n",
    "b_m = b.getRoot()\n",
    "z_m = z.getRoot()\n",
    "\n",
    "canvas = createCanvas(a, b, z)\n",
    "\n",
    "for m, (z_ref, (mask_k, a_k, b_k)) in z_m << (a_m | b_m):\n",
    "    for k, (ab_mask, a_val, b_val) in a_k | b_k:\n",
    "        print(f\"Processing: [{k} -> ( {z_ref}, ({ab_mask}, {a_val}, {b_val})]\")\n",
    "\n",
    "        z_ref += a_val + b_val\n",
    "        canvas.addActivity((m, k), (m, k), (m,))\n",
    "\n",
    "\n",
    "displayCanvas(canvas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other binary operators\n",
    "\n",
    "Other binary operators on fibers include **difference** (-) and **exclusive or** (^). Note **exclusive or** returns a mask like **or**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Tensor.fromYAMLfile(datafileName(\"elementwise-a.yaml\"))\n",
    "b = Tensor.fromYAMLfile(datafileName(\"elementwise-b.yaml\"))\n",
    "\n",
    "\n",
    "a_m = a.getRoot()\n",
    "b_m = b.getRoot()\n",
    "\n",
    "z_m = a_m - b_m\n",
    "z2_m = a_m ^ b_m \n",
    "\n",
    "print(\"Fiber a_m\")\n",
    "displayTensor(a_m)\n",
    "\n",
    "print(\"Fiber b_m\")\n",
    "displayTensor(b_m)\n",
    "\n",
    "print(\"Fiber a_m - b_m\")\n",
    "displayTensor(z_m)\n",
    "\n",
    "print(\"Fiber a_m ^ b_m\")\n",
    "displayTensor(z2_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce vector to a rank zero tensor\n",
    "\n",
    "A final example illustrating reducing the elements of a fiber into a rank-0 tensor, which is created using a tensor with an empty set of rank_ids.\n",
    "\n",
    "Note: we currently need to specifiy a constanst highlight coordinate for the rank-0 tensor..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Tensor.fromYAMLfile(datafileName(\"elementwise-a.yaml\"))\n",
    "z = Tensor(rank_ids=[])\n",
    "\n",
    "a_m = a.getRoot()\n",
    "z_ref = z.getRoot()\n",
    "\n",
    "canvas = createCanvas(a, z)\n",
    "\n",
    "for m, (a_val) in a_m:\n",
    "    z_ref += a_val\n",
    "    canvas.addActivity((m,), (0,))\n",
    "\n",
    "displayCanvas(canvas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing area\n",
    "\n",
    "For running alternative algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
