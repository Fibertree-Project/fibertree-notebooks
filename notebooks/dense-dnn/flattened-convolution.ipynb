{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Flattened 1-D Multi-Input Channel Convolution\n",
    "\n",
    "This notebook uses the fiber-tree emulator to display the behaviour of flattening multiple input channel 1-D into a simple 1-D convolution of a single channel. \n",
    "\n",
    "Note this notebook relies on the invariant that the data is dense. Therefore, because the data is assumed to be dense we can use the position-based operators on the premise that for dense data the position and coordinate are the same.\n",
    "\n",
    "First, include some libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Begin - startup boilerplate code\n",
    "\n",
    "import pkgutil\n",
    "\n",
    "if 'fibertree_bootstrap' not in [pkg.name for pkg in pkgutil.iter_modules()]:\n",
    "  !python3 -m pip  install git+https://github.com/Fibertree-project/fibertree-bootstrap --quiet\n",
    "\n",
    "# End - startup boilerplate code\n",
    "\n",
    "from fibertree_bootstrap import *\n",
    "\n",
    "fibertree_bootstrap(style=\"uncompressed\", animation=\"movie\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enable_log = False\n",
    "\n",
    "def set_params(log):\n",
    "    global enable_log\n",
    "\n",
    "    enable_log = (log == 'enable')\n",
    "\n",
    "def log(*args):\n",
    "    if enable_log:\n",
    "        print(*args)\n",
    "\n",
    "controls = interactive(set_params,\n",
    "                       log=['disable', 'enable'])\n",
    "\n",
    "\n",
    "display(controls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution Inputs Selection\n",
    "\n",
    "Using sliders to select the shapes of the weights and input activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 2\n",
    "S = 3\n",
    "W = 8\n",
    "\n",
    "\n",
    "tm = TensorMaker(\"toeplitz\")\n",
    "\n",
    "tm.addTensor(\"I_CW\",\n",
    "             rank_ids=[\"C\", \"W\"],\n",
    "             shape=[C, W],\n",
    "             density=1,\n",
    "             interval=5,\n",
    "             seed=0,\n",
    "             color=\"blue\")\n",
    "\n",
    "tm.addTensor(\"F_CS\",\n",
    "             rank_ids=[\"C\", \"S\"],\n",
    "             shape=[C, S],\n",
    "             density=1,\n",
    "             interval=5,\n",
    "             seed=0,\n",
    "             color=\"green\")\n",
    "\n",
    "tm.displayControls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Input Tensors\n",
    "\n",
    "Given shapes selected above create and display the filter weights (**f**) and input activations (**i**) and a reference output (**o_verify**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_CW = tm.makeTensor(\"I_CW\")\n",
    "F_CS = tm.makeTensor(\"F_CS\")\n",
    "\n",
    "print(\"Input activations\")\n",
    "displayTensor(I_CW)\n",
    "print(\"Filter weights\")\n",
    "displayTensor(F_CS)\n",
    "\n",
    "C = I_CW.getShape(\"C\")\n",
    "W = I_CW.getShape(\"W\")\n",
    "S = F_CS.getShape(\"S\")\n",
    "\n",
    "Q = W - S + 1\n",
    "\n",
    "print(\"\")\n",
    "print(f\"Output activations - {Q}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verification Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_raw = I_CW.getRoot().uncompress()\n",
    "f_raw = F_CS.getRoot().uncompress()\n",
    "o_verify_raw = Q*[0]\n",
    "\n",
    "print(f\"I: {i_raw}\")\n",
    "print(f\"F: {f_raw}\")\n",
    "\n",
    "for q in range(Q):\n",
    "    for c in range(C):\n",
    "        for s in range(S):\n",
    "            w = q + s\n",
    "            o_verify_raw[q] += i_raw[c][w] * f_raw[c][s]\n",
    "        \n",
    "print(f\"O_verify: {o_verify_raw}\")\n",
    "\n",
    "o_verify = Tensor.fromUncompressed(name=\"O_verify\",\n",
    "                                   rank_ids=[\"Q\"],\n",
    "                                   shape=[Q],\n",
    "                                   root=o_verify_raw,\n",
    "                                   default=None)\n",
    "\n",
    "displayTensor(o_verify)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Input Channel Convolution\n",
    "\n",
    "Process the convolution of the multi-channel input activation and filter weight tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o = Tensor.makePopulated(name=\"O\",\n",
    "                         rank_ids=[\"Q\"],\n",
    "                         shape=[Q])\n",
    "\n",
    "print(\"Convolution\")\n",
    "\n",
    "i = I_CW\n",
    "f = F_CS\n",
    "\n",
    "canvas = createCanvas(f, i, o)\n",
    "\n",
    "for q in range(Q):\n",
    "    log(f\"Processing output: ({q}, ({o[q]}))\")\n",
    "    for c in range(C):\n",
    "        for w in range(W):\n",
    "            s = w - q\n",
    "            if s < 0 or s >= S: continue\n",
    "            log(f\"Processing input: ({c}, {w}, {i[c][w]})\")\n",
    "            log(f\"  Processing filter weight ({c}, {s}, {f[c][s]})\")\n",
    "            o[q] += f[c][s] * i[c][w]\n",
    "\n",
    "            canvas.addActivity((), [(c, w,) for w in range(q, q+S)], (), worker=\"W\")\n",
    "            canvas.addFrame((c, s,), (c, w,), (q,))\n",
    "\n",
    "displayTensor(o)\n",
    "displayCanvas(canvas)\n",
    "\n",
    "print(\"Input Activations - before\")\n",
    "assert o == o_verify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flatten Inputs and Filters\n",
    "\n",
    "Flatten the input activations and filter weights into a single input channel.\n",
    "\n",
    "Note: The rank_id and shape of the tensor are changed as the coordinates are updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Filter Weights - before\")\n",
    "displayTensor(f)\n",
    "\n",
    "f_flat = f.swapRanks().flattenRanks()\n",
    "f_flat.getRoot().updateCoords(lambda pos, c, p: (c[0]*C)+c[1],\n",
    "                              new_rank_id=\"CS\",\n",
    "                              new_shape=C*S)\n",
    "f_flat.setName(\"F_flat\")\n",
    "\n",
    "print(\"Filter Weights - after\")\n",
    "displayTensor(f_flat)\n",
    "\n",
    "\n",
    "print(\"Input Activations - before\")\n",
    "displayTensor(i)\n",
    "\n",
    "i_flat = i.swapRanks().flattenRanks()\n",
    "i_flat.getRoot().updateCoords(lambda pos, c, p: (c[0]*C)+c[1],\n",
    "                              new_rank_id=\"CW\",\n",
    "                              new_shape=C*W)\n",
    "i_flat.setName(\"I_flat\")\n",
    "\n",
    "print(\"Input Activations - after\")\n",
    "displayTensor(i_flat)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flattened convolution\n",
    "\n",
    "Process a convolution on the flattened input activations and filter weights. Note that the window now slides by ```C``` the number of inputs channels.\n",
    "\n",
    "Note, this processing pattern is the same as used by Eyeriss for processing multiple input channels at once in a single PE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o = Tensor.makePopulated(name=\"O\",\n",
    "                         rank_ids=[\"Q\"],\n",
    "                         shape=[Q])\n",
    "\n",
    "\n",
    "print(\"Convolution\")\n",
    "\n",
    "\n",
    "canvas = createCanvas(f_flat, i_flat, o)\n",
    "\n",
    "for q in range(Q):\n",
    "    log(f\"Processing output: ({q}, ({o[q]}))\")\n",
    "    for cw in range(C*W):\n",
    "        cs = cw - C*q\n",
    "        if cs < 0 or cs >= C*S: continue\n",
    "        log(f\"Processing input: ({cw}, {i_flat[cw]})\")\n",
    "        log(f\"  Processing filter weight ({cs}, {f_flat[cs]})\")\n",
    "        o[q] += f_flat[cs] * i_flat[cw]\n",
    "\n",
    "        i_window = [(cw,) for cw in range(C*q, C*q+C*S)]\n",
    "        canvas.addActivity((), i_window, (), spacetime=(\"W\", (q, cw)))\n",
    "        canvas.addActivity((cs,), (cw,), (q,), spacetime=(\"P\", (q, cw)))\n",
    "\n",
    "displayTensor(o)\n",
    "displayCanvas(canvas)\n",
    "\n",
    "assert o == o_verify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing area\n",
    "\n",
    "For running alternative algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
