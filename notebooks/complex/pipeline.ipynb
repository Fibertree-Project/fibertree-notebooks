{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline \n",
    "\n",
    "Model a simple pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Begin - startup boilerplate code\n",
    "\n",
    "import pkgutil\n",
    "\n",
    "if 'fibertree_bootstrap' not in [pkg.name for pkg in pkgutil.iter_modules()]:\n",
    "  !python3 -m pip  install git+https://github.com/Fibertree-project/fibertree-bootstrap --quiet\n",
    "\n",
    "# End - startup boilerplate code\n",
    "\n",
    "\n",
    "from fibertree_bootstrap import *\n",
    "fibertree_bootstrap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "s0 = Tensor.fromRandom([\"X\"], [10], [0.5], 10, seed=3, name=\"s0\")\n",
    "displayTensor(s0)\n",
    "print(f\"{s0:n*}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple 3-stage pipeline\n",
    "\n",
    "Each stage processes (adds one to) the elements of a rank-1 tensor (one element per cycle) and passes the result to the next stage. There is a delay of **stage_delay** cycles between the generation of a result and its use in the next stage.\n",
    "\n",
    "Note that the intermediate buffers between stages are represented as a full tensor, although the actually occupancy of the buffer at any cycle will be much less than the entire length of the tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "s1 = Tensor(rank_ids=[\"X\"], name=\"s1\")\n",
    "s2 = Tensor(rank_ids=[\"X\"], name=\"s2\")\n",
    "s3 = Tensor(rank_ids=[\"X\"], name=\"s3\")\n",
    "\n",
    "stage_delay = 3\n",
    "\n",
    "canvas = createCanvas(s0, s1, s2, s3, enable_wait=True)\n",
    "\n",
    "s0_x = s0.getRoot()\n",
    "s1_x = s1.getRoot()\n",
    "s2_x = s2.getRoot()\n",
    "s3_x = s3.getRoot()\n",
    "\n",
    "cycle= 0\n",
    "\n",
    "# Stage 1\n",
    "\n",
    "for x0, (s1_ref, s0_val) in s1_x << s0_x:\n",
    "    s1_ref <<= s0_val+1\n",
    "    canvas.addActivity((x0,), (x0,), (), (), worker=\"PE0\", skew=cycle)\n",
    "    cycle += 1\n",
    "\n",
    "# Stage 1\n",
    "\n",
    "for x1, (s2_ref, s1_val) in s2_x << s1_x:\n",
    "    s2_ref <<= s1_val+1\n",
    "    canvas.addActivity((), (x1,), (x1,), (), worker=\"PE1\", wait={\"s1\":stage_delay})\n",
    "\n",
    "# Stage 3\n",
    "\n",
    "for x2, (s3_ref, s2_val) in s3_x << s2_x:\n",
    "    s3_ref <<= s2_val+1\n",
    "    canvas.addActivity((), (), (x2,), (x2,), worker=\"PE2\", wait={\"s2\":stage_delay})\n",
    "\n",
    "        \n",
    "displayCanvas(canvas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two-stage parallel pipeline\n",
    "\n",
    "Each stage processes (adds one to) the elements of a rank-1 tensor (#PEs elements per cycle) and passes the results to the next stage. The parallelism is represented by a splitting of the input tensor via **splitEqual()** into the work for each cycle. There is a delay of **stage_delay** cycles between the generation of a result and its use in the next stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "s1 = Tensor(rank_ids=[\"X.1\", \"X.0\"], name=\"s1\")\n",
    "s2 = Tensor(rank_ids=[\"X.1\", \"X.0\"], name=\"s2\")\n",
    "s3 = Tensor(rank_ids=[\"X\"], name=\"s3\")\n",
    "\n",
    "NUM_PEs = 2\n",
    "stage_delay = 2\n",
    "\n",
    "s0_split = s0.splitEqual(NUM_PEs)\n",
    "\n",
    "canvas = createCanvas(s0_split, s1, s2, enable_wait=True)\n",
    "\n",
    "s0_split_x1 = s0_split.getRoot()\n",
    "s1_x1 = s1.getRoot()\n",
    "s2_x1 = s2.getRoot()\n",
    "s3_x = s3.getRoot()\n",
    "\n",
    "cycle = CycleManager()\n",
    "\n",
    "# Stage 1\n",
    "\n",
    "for x1, (s1_x0, s0_x0) in s1_x1 << s0_split_x1:\n",
    "    cycle.startParallel()\n",
    "    for pe, (x0, (s1_ref, s0_val)) in enumerate(s1_x0 << s0_x0):\n",
    "        cycle.startWorker()\n",
    "        s1_ref <<= s0_val+1\n",
    "        canvas.addActivity((x1,x0), (x1,x0), worker=f\"S1-PE{pe}\", skew=cycle())\n",
    "        cycle.finishWorker()\n",
    "    cycle.finishParallel()\n",
    "\n",
    "# Stage 1\n",
    "\n",
    "for x1, (s2_x0, s1_x0) in s2_x1 << s1_x1:\n",
    "    for pe, (x0, (s2_ref, s1_val)) in enumerate(s2_x0 << s1_x0):\n",
    "        s2_ref <<= s1_val+1\n",
    "        canvas.addActivity((), (x1,x0), (x1,x0), worker=f\"S2-PE{pe}\", wait={\"s1\":stage_delay})\n",
    "\n",
    "\n",
    "        \n",
    "displayCanvas(canvas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
